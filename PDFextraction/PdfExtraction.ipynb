{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a951d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/baba1903/anaconda3/lib/python3.10/site-packages (1.30.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: certifi in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135bcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import base64\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a938e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_path():\n",
    "    \"\"\"\n",
    "    Opens a file dialog to allow the user to select a folder from their system.\n",
    "\n",
    "    Returns:\n",
    "        str: The file path of the selected folder.\n",
    "    \"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    return filedialog.askdirectory()\n",
    "\n",
    "def get_relevant_sustainability_report_pages(path, search_terms):\n",
    "    \"\"\"\n",
    "    Extracts pages from a PDF file that contain specified search terms.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): The file path of the PDF document.\n",
    "        search_terms (list of str): A list of terms to search within the PDF.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are search terms and values are sets of page numbers where these terms were found.\n",
    "    \"\"\"\n",
    "    company_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    \n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        \n",
    "        # Print some information about the PDF\n",
    "        print(f\"{company_name} - Length of report: {len(pdf.pages)} pages\")\n",
    "        \n",
    "        terms_pages = {}  # Dictionary to store terms and their corresponding pages as sets\n",
    "\n",
    "        # Initialize dictionary with each term and an empty set\n",
    "        for term in search_terms:\n",
    "            terms_pages[term] = set()\n",
    "\n",
    "        # Loop through all the pages\n",
    "        for i in range(len(pdf.pages)):\n",
    "\n",
    "#             print(\"Page: \", i+1)\n",
    "\n",
    "            page = pdf.pages[i]\n",
    "            text = page.extract_text().lower()\n",
    "            \n",
    "            # Check if any of the terms are in the text\n",
    "            for term in search_terms:\n",
    "                if term in text:\n",
    "                    print(f\"Term '{term}' found on page {i+1}\")\n",
    "                    terms_pages[term].add(i + 1)  # Add page number to the corresponding term's set\n",
    "\n",
    "        return terms_pages\n",
    "\n",
    "def save_pages_as_images(path, terms_pages):\n",
    "    \"\"\"\n",
    "    Saves specific pages of a PDF file as images in a newly created folder.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): The file path of the PDF document.\n",
    "        terms_pages (dict): A dictionary with terms as keys and sets of page numbers as values.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of paths to the saved image files.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Initialize list to store the paths of the saved images\n",
    "    saved_images = []\n",
    "\n",
    "    # Extract the file name without extension and create a new folder\n",
    "    folder_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for term, pages in terms_pages.items():\n",
    "            for page_number in pages:\n",
    "                page = pdf.pages[page_number - 1]\n",
    "                image = page.to_image(resolution=300)\n",
    "                image_path = os.path.join(folder_name, f\"page_{page_number}_{term.replace(' ', '_')}.png\")\n",
    "                image.save(image_path, format=\"PNG\")\n",
    "                saved_images.append(image_path)\n",
    "\n",
    "    return saved_images\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encodes an image file to a base64 string.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): The file path of the image to be encoded.\n",
    "\n",
    "    Returns:\n",
    "        str: The base64 encoded string of the image.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def extract_and_query_emission_intensity(pdf_folder, api_key, search_terms):\n",
    "    \"\"\"\n",
    "    Extracts relevant pages from a PDF, saves them as images, and queries an API to find emission intensities from these images.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path of the PDF document.\n",
    "        api_key (str): API key for the OpenAI service.\n",
    "        search_terms (list of str): Terms to search within the PDF for relevant pages.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints out the emission intensities and their units if found.\n",
    "    \"\"\"    \n",
    "    for pdf_file in os.listdir(pdf_folder):\n",
    "        if pdf_file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "            base_name = os.path.splitext(pdf_file)[0]\n",
    "            parts = base_name.rsplit('_')\n",
    "            company_name = parts[0].lower().strip()\n",
    "    \n",
    "    \n",
    "            # Extract relevant pages and save them as images\n",
    "            terms_pages = get_relevant_sustainability_report_pages(pdf_path, search_terms)\n",
    "            saved_images = save_pages_as_images(pdf_path, terms_pages)\n",
    "\n",
    "            # Prepare the message content with all the images\n",
    "            message_content = [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\"The images are screenshots from a company's sustainability report. I am interested in extracting the companies emission intensity (that is, their GHG emissions per tonne or kg of production), which is usually a number between 0.1 and 2 (when presented in t CO2e per t product), or between 100 and 2000 (when presented in kg CO2 per t product). If years are given, please find the emission intensity for the latest year. This information might sit in a bar chart or line graph. Can you please extract the emission intensity and its unit from the text in these images? Return it in tags (e.g. <emission_intensity>0.74</emission_intensity><unit>t CO2e / t</unit>, or <emission_intensity>740</emission_intensity><unit>kg CO2e / t</unit>) (If you cannot find the emission intensity, return <emission_intensity>N/A</emission_intensity>).\\n\"\n",
    "                             \"Emission intensity can also be refereed to as:\\n\"\n",
    "                             \"Carbon Intensity,Greenhouse Gas Intensity (GHG Intensity),Emissions Per Unit of Production,CO2 Emissions per Dollar of Revenue,Carbon Footprint per Unit,Emissions Ratio,CO2 Emissions per Energy Produced,Carbon Efficiency,Carbon Intensity Metric,CO2 Intensity\"\n",
    "                            )\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            # Add all images to the message content\n",
    "            for image_path in saved_images:\n",
    "                base64_image = encode_image_to_base64(image_path)\n",
    "                message_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Create the OpenAI client\n",
    "            client = OpenAI(api_key=api_key)\n",
    "\n",
    "            # Send the request\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": message_content}],\n",
    "                max_tokens=300,\n",
    "            )\n",
    "\n",
    "            # Extract the emission intensity and unit from the response\n",
    "            response_text = response.choices[0].message.content\n",
    "            print(\"Response Text:\", response_text)\n",
    "            \n",
    "            emission_intensities = re.findall(r\"<emission_intensity>(.*?)</emission_intensity><unit>(.*?)</unit>\", response_text)\n",
    "\n",
    "            # Print the results\n",
    "            for intensity, unit in emission_intensities:\n",
    "                print(f\"{company_name} - Emission intensity: {intensity} {unit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4658ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 15:44:58.441 python[4107:104193] +[CATransaction synchronize] called within transaction\n",
      "2024-06-24 15:44:58.560 python[4107:104193] +[CATransaction synchronize] called within transaction\n",
      "2024-06-24 15:45:01.943 python[4107:104193] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foshan Haitian Flavouring and Food_Sustainability Report_2022 - Length of report: 76 pages\n",
      "Term 'ghg emission' found on page 42\n",
      "Response Text: The provided image contains text discussing energy conservation, emission reduction, and waste management for a company, but it does not contain specific figures for emission intensity (i.e., their GHG emissions per tonne or kg of production). The text mentions the reduction of GHG emissions in absolute terms and several projects that helped to achieve these reductions, but without relating these figures to the company's production volume, which is necessary to calculate the emission intensity.\n",
      "\n",
      "Therefore, based on the available information in the image, the emission intensity cannot be determined:\n",
      "\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "Campbell Soup_Sustainability Report_2023 - Length of report: 21 pages\n",
      "Term 'ghg emission' found on page 3\n",
      "Response Text: <emission_intensity>N/A</emission_intensity>\n",
      "Ingredion_Sustainability Report_2022 - Length of report: 66 pages\n",
      "Term 'ghg emission' found on page 6\n",
      "Term 'emission intensity' found on page 57\n",
      "Term 'ghg emission' found on page 57\n",
      "Term 'ghg emission' found on page 66\n",
      "Response Text: The images provided are parts of a sustainability report from a company. However, none of the images contain specific numerical data about the company's emission intensity (GHG emissions per tonne or kg of production).\n",
      "\n",
      "The first two images mention \"GHG emission intensity\" in their content index under the emissions section but do not provide specific values. It references the 2022 CDP Climate Change report for more information.\n",
      "\n",
      "The third image does not mention GHG emission intensity at all.\n",
      "\n",
      "The fourth image displays a sustainability goals progress summary with various environmental targets, but it does not provide any numerical emission intensity data.\n",
      "\n",
      "Based on the information available in the images, I cannot extract the company's emission intensity. The actual numerical data may be found in a different section of the report or in the referenced CDP Climate Change report. To obtain the specific emission intensity figure, you may need to refer to those documents.\n",
      "\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "NISSIN FOODS_Sustainability Report_2021 - Length of report: 35 pages\n",
      "Term 'ghg emission' found on page 9\n",
      "Term 'ghg emission' found on page 10\n",
      "Term 'ghg emission' found on page 32\n",
      "Term 'emissions intensity' found on page 33\n",
      "Response Text: The screenshots provided contain information about the company's greenhouse gas (GHG) emissions scope, aggregation period, calculation methods, and the totals of Scope 1, 2, and 3 GHG emissions over different years. However, none of the images include a specific emission intensity metric presented as GHG emissions per tonne/kg of production, which you have asked for.\n",
      "\n",
      "Typically, emission intensity would be displayed as a separate figure that directly relates GHG emissions to the amount of production, often in terms of tonnes of CO2e per tonne of product produced. Since such a figure is not available in the provided screenshots, I am unable to extract the desired emission intensity measure.\n",
      "\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "HAIN CELESTIAL_Sustainability Report_2023 - Length of report: 52 pages\n",
      "Term 'ghg emission' found on page 10\n",
      "Term 'ghg emission' found on page 46\n",
      "Response Text: <emission_intensity>N/A</emission_intensity>\n",
      "danone_Sustainability Report_2022 - Length of report: 7 pages\n",
      "Response Text: <emission_intensity>N/A</emission_intensity>\n",
      "Freshpet_Sustainability Report_2023 - Length of report: 67 pages\n",
      "Term 'emission intensity' found on page 35\n",
      "Term 'ghg emission' found on page 35\n",
      "Term 'ghg emission' found on page 48\n",
      "Response Text: The images provided are parts of the sustainability report for the company Freshpet. The specific information on emission intensity per ton or kg of production is not explicitly stated in these images. The images do include general GHG emissions data and percentages of change year after year but do not provide the exact emission intensity figure with the required production volume units for the most recent year.\n",
      "\n",
      "There are references to the change in GHG intensity, but this is stated as a percentage change rather than a specific number with a unit of measurement that can be related back to the amount of product produced. To give you an accurate emission intensity figure, one would need the actual CO2e emissions data and the total production volume for the same year.\n",
      "\n",
      "Since the necessary information is not available in the given images, I must return the following response:\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "China Feihe_Sustainability Report_2023 - Length of report: 55 pages\n",
      "Term 'ghg emission' found on page 9\n",
      "Term 'ghg emission' found on page 40\n",
      "Response Text: I'm sorry, but after reviewing the provided images, the specific information you requested regarding emission intensity (GHG emissions per tonne or kg of production) is not visibly present in the text or charts. There are several environmental performance metrics listed, but none that directly provide the emission intensity figure as defined in your request.\n",
      "\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "GRUPO BIMBO_Sustainability Report_2023 - Length of report: 377 pages\n",
      "Term 'ghg emission' found on page 272\n",
      "Term 'emissions intensity' found on page 281\n",
      "Term 'ghg emission' found on page 281\n",
      "Response Text: The images provided contain information on greenhouse gas emissions, but they do not directly provide the emission intensity (GHG emissions per unit of production) in a numerical value. Instead, they reference certain GRI (Global Reporting Initiative) Standards sections and overall GHG emissions in tons. To calculate emission intensity, the total emissions would need to be divided by the total production in tons, which isn't available in these images.\n",
      "\n",
      "If there are additional parts of the report that include production figures alongside the emission data, please provide them to facilitate the calculation of the emission intensity. Otherwise, based on the information provided in the images, the emission intensity cannot be determined.\n",
      "\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "Yakult Honsha_Sustainability Report_2023 - Length of report: 115 pages\n",
      "Term 'ghg emission' found on page 3\n",
      "Term 'ghg emission' found on page 14\n",
      "Term 'ghg emission' found on page 25\n",
      "Term 'ghg emission' found on page 26\n",
      "Term 'ghg emission' found on page 30\n",
      "Term 'ghg emission' found on page 33\n",
      "Term 'ghg emission' found on page 66\n",
      "Term 'ghg emission' found on page 104\n",
      "Response Text: The images provided, which appear to be pages from Yakult's Sustainability Report 2023, do not contain specific numerical information regarding the company's emission intensity (GHG emissions per tonne or kg of production). There are discussions about reducing GHG emissions, climate change initiatives, and progress toward targets, but they do not provide a clear numerical value for emission intensity.\n",
      "\n",
      "Therefore, the data you have requested cannot be found in the provided screenshots. The appropriate response to convey this is:\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "McCormick & Co_Sustainability Report_2023 - Length of report: 132 pages\n",
      "Term 'ghg emission' found on page 1\n",
      "Term 'ghg emission' found on page 29\n",
      "Term 'ghg emission' found on page 56\n",
      "Term 'ghg emission' found on page 64\n",
      "Term 'ghg emission' found on page 80\n",
      "Term 'intensity figure' found on page 81\n",
      "Term 'ghg emission' found on page 81\n",
      "Term 'ghg emission' found on page 84\n",
      "Term 'ghg emission' found on page 108\n",
      "Term 'ghg emission' found on page 120\n",
      "Response Text: <emission_intensity>5.22</emission_intensity><unit>t CO2e / t</unit>\n",
      "mccormick & co - Emission intensity: 5.22 t CO2e / t\n",
      "Conagra Brands_Sustainability Report_2023 copy - Length of report: 56 pages\n",
      "Term 'ghg emission' found on page 50\n",
      "Response Text: The text provided in this image appears to be discussing Conagra Brands' sustainability practices, deforestation policies, diversity and inclusion efforts, and packaging waste management. However, the specific information you are looking for—emission intensity (GHG emissions per unit of production)—is not visible within the text of this image. Therefore, based on the content provided here, we cannot extract the companies emission intensity.\n",
      "\n",
      "<emission_intensity>N/A</emission_intensity>\n",
      "McCormick & Co_Sustainability Report_2023 copy - Length of report: 43 pages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Text: <emission_intensity>N/A</emission_intensity>\n",
      "LINDT & SPRUENGLI_Sustainability Report_2023 - Length of report: 155 pages\n",
      "Term 'ghg emission' found on page 9\n",
      "Term 'ghg emission' found on page 61\n",
      "Term 'ghg emission' found on page 70\n",
      "Term 'ghg emission' found on page 72\n",
      "Term 'ghg emission' found on page 106\n",
      "Term 'ghg emission' found on page 130\n",
      "Term 'ghg emission' found on page 138\n",
      "Response Text: The relevant data to calculate the emission intensity can be found in these images. On one of the pages, it lists the total GHG emissions for the company as 3.7 million tonnes CO2 equivalent. On another page, it lists the total production in metric tons as 116,273 metric tons.\n",
      "\n",
      "To calculate the emission intensity, you would divide the total GHG emissions by the total production:\n",
      "\n",
      "Emission intensity = Total GHG emissions / Total production\n",
      "Emission intensity = 3,700,000 tonnes CO2e / 116,273 metric tons\n",
      "Emission intensity ≈ 31.83 t CO2e / metric ton product\n",
      "\n",
      "Now we can represent this in the requested tag format:\n",
      "\n",
      "<emission_intensity>31.83</emission_intensity><unit>t CO2e / t</unit>\n",
      "lindt & spruengli - Emission intensity: 31.83 t CO2e / t\n",
      "Mondelez International_Sustainability Report_2023 - Length of report: 84 pages\n",
      "Term 'ghg emission' found on page 3\n",
      "Term 'ghg emission' found on page 21\n",
      "Term 'emissions intensity' found on page 22\n",
      "Term 'ghg emission' found on page 23\n",
      "Term 'ghg emission' found on page 24\n",
      "Term 'emissions intensity' found on page 25\n",
      "Term 'ghg emission' found on page 47\n",
      "Term 'ghg emission' found on page 48\n",
      "Term 'ghg emission' found on page 50\n",
      "Term 'ghg emission' found on page 51\n",
      "Term 'ghg emission' found on page 78\n",
      "Term 'ghg emission' found on page 80\n",
      "Response Text: <emission_intensity>N/A</emission_intensity>\n",
      "Barry Callebaut_Sustainability Report_2023 - Length of report: 64 pages\n",
      "Term 'ghg emission' found on page 15\n",
      "Term 'ghg emission' found on page 19\n",
      "Term 'ghg emission' found on page 26\n",
      "Term 'ghg emission' found on page 27\n",
      "Term 'ghg emission' found on page 28\n",
      "Term 'ghg emission' found on page 29\n",
      "Term 'ghg emission' found on page 30\n",
      "Term 'ghg emission' found on page 31\n",
      "Term 'emissions intensity' found on page 32\n",
      "Term 'intensity figure' found on page 32\n",
      "Term 'ghg emission' found on page 32\n",
      "Term 'ghg emission' found on page 34\n",
      "Term 'ghg emission' found on page 35\n",
      "Term 'emissions intensity' found on page 48\n",
      "Term 'emissions intensity' found on page 50\n",
      "Term 'ghg emission' found on page 53\n",
      "Term 'ghg emission' found on page 57\n",
      "Term 'ghg emission' found on page 58\n",
      "Term 'ghg emission' found on page 59\n",
      "Term 'ghg emission' found on page 60\n",
      "Term 'ghg emission' found on page 61\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4-vision-preview in organization org-lnKIIWUzgB6GQfRtYE0EDJQ3 on tokens per min (TPM): Limit 10000, Requested 16351. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m\n\u001b[1;32m      3\u001b[0m common_terms \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memissions intensity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memission intensity\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO2 Intensity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m         ]\n\u001b[1;32m     25\u001b[0m pdf_folder \u001b[38;5;241m=\u001b[39m get_folder_path()\n\u001b[0;32m---> 27\u001b[0m \u001b[43mextract_and_query_emission_intensity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommon_terms\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 147\u001b[0m, in \u001b[0;36mextract_and_query_emission_intensity\u001b[0;34m(pdf_folder, api_key, search_terms)\u001b[0m\n\u001b[1;32m    144\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4-vision-preview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Extract the emission intensity and unit from the response\u001b[39;00m\n\u001b[1;32m    154\u001b[0m response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1004\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Request too large for gpt-4-vision-preview in organization org-lnKIIWUzgB6GQfRtYE0EDJQ3 on tokens per min (TPM): Limit 10000, Requested 16351. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "api_key = \"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\"\n",
    "\n",
    "common_terms = [\n",
    "            'emissions intensity',\n",
    "            'emission intensity',\n",
    "            'intensity figure',\n",
    "            'scope 1 and 2 emissions intensity',\n",
    "            'scope 1+2 emissions intensity',\n",
    "            'intensity of energy consumption during production',\n",
    "            'intensity of water consumption related to production',\n",
    "            'ghg emission',\n",
    "            'Carbon Intensity',\n",
    "            'Greenhouse Gas Intensity',\n",
    "            'GHG Intensity',\n",
    "            'Emissions Per Unit of Production',\n",
    "            'CO2 Emissions per Dollar of Revenue',\n",
    "            'Carbon Footprint per Unit',\n",
    "            'Emissions Ratio',\n",
    "            'CO2 Emissions per Energy Produced',\n",
    "            'Carbon Efficiency',\n",
    "            'Carbon Intensity Metric',\n",
    "            'CO2 Intensity'\n",
    "        ]\n",
    "\n",
    "pdf_folder = get_folder_path()\n",
    "\n",
    "extract_and_query_emission_intensity(pdf_folder, api_key, common_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e8642",
   "metadata": {},
   "source": [
    "**When there's a 'RateLimitError', you might want to leave that file out of the folder and return to it after. You could potentially add a for loop to deal with this error or reduce the common terms for that file**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
