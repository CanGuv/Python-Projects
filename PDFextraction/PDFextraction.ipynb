{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a951d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/baba1903/anaconda3/lib/python3.10/site-packages (1.30.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: certifi in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/baba1903/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135bcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import base64\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a938e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_path():\n",
    "    \"\"\"\n",
    "    Opens a file dialog to allow the user to select a folder from their system.\n",
    "\n",
    "    Returns:\n",
    "        str: The file path of the selected folder.\n",
    "    \"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    return filedialog.askdirectory()\n",
    "\n",
    "def get_relevant_sustainability_report_pages(path, search_terms):\n",
    "    \"\"\"\n",
    "    Extracts pages from a PDF file that contain specified search terms.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): The file path of the PDF document.\n",
    "        search_terms (list of str): A list of terms to search within the PDF.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are search terms and values are sets of page numbers where these terms were found.\n",
    "    \"\"\"\n",
    "    company_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    \n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        \n",
    "        # Print some information about the PDF\n",
    "        print(f\"{company_name} - Length of report: {len(pdf.pages)} pages\")\n",
    "        \n",
    "        terms_pages = {}  # Dictionary to store terms and their corresponding pages as sets\n",
    "\n",
    "        # Initialize dictionary with each term and an empty set\n",
    "        for term in search_terms:\n",
    "            terms_pages[term] = set()\n",
    "\n",
    "        # Loop through all the pages\n",
    "        for i in range(len(pdf.pages)):\n",
    "\n",
    "#             print(\"Page: \", i+1)\n",
    "\n",
    "            page = pdf.pages[i]\n",
    "            text = page.extract_text().lower()\n",
    "            \n",
    "            # Check if any of the terms are in the text\n",
    "            for term in search_terms:\n",
    "                if term in text:\n",
    "                    print(f\"Term '{term}' found on page {i+1}\")\n",
    "                    terms_pages[term].add(i + 1)  # Add page number to the corresponding term's set\n",
    "\n",
    "        return terms_pages\n",
    "\n",
    "def save_pages_as_images(path, terms_pages):\n",
    "    \"\"\"\n",
    "    Saves specific pages of a PDF file as images in a newly created folder.\n",
    "\n",
    "    Parameters:\n",
    "        path (str): The file path of the PDF document.\n",
    "        terms_pages (dict): A dictionary with terms as keys and sets of page numbers as values.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of paths to the saved image files.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Initialize list to store the paths of the saved images\n",
    "    saved_images = []\n",
    "\n",
    "    # Extract the file name without extension and create a new folder\n",
    "    folder_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for term, pages in terms_pages.items():\n",
    "            for page_number in pages:\n",
    "                page = pdf.pages[page_number - 1]\n",
    "                image = page.to_image(resolution=300)\n",
    "                image_path = os.path.join(folder_name, f\"page_{page_number}_{term.replace(' ', '_')}.png\")\n",
    "                image.save(image_path, format=\"PNG\")\n",
    "                saved_images.append(image_path)\n",
    "\n",
    "    return saved_images\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encodes an image file to a base64 string.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): The file path of the image to be encoded.\n",
    "\n",
    "    Returns:\n",
    "        str: The base64 encoded string of the image.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def extract_and_query_emission_intensity(pdf_folder, api_key, search_terms):\n",
    "    \"\"\"\n",
    "    Extracts relevant pages from a PDF, saves them as images, and queries an API to find emission intensities from these images.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path of the PDF document.\n",
    "        api_key (str): API key for the OpenAI service.\n",
    "        search_terms (list of str): Terms to search within the PDF for relevant pages.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints out the values you are looking for.\n",
    "    \"\"\"    \n",
    "    for pdf_file in os.listdir(pdf_folder):\n",
    "        if pdf_file.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    \n",
    "            # Extract relevant pages and save them as images\n",
    "            terms_pages = get_relevant_sustainability_report_pages(pdf_path, search_terms)\n",
    "            saved_images = save_pages_as_images(pdf_path, terms_pages)\n",
    "\n",
    "            # Prepare the message content with all the images\n",
    "            message_content = [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": (\"\") # Message containing instructions and what to extract\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            # Add all images to the message content\n",
    "            for image_path in saved_images:\n",
    "                base64_image = encode_image_to_base64(image_path)\n",
    "                message_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Create the OpenAI client\n",
    "            client = OpenAI(api_key=api_key)\n",
    "\n",
    "            # Send the request\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[{\"role\": \"user\", \"content\": message_content}],\n",
    "                max_tokens=300,\n",
    "            )\n",
    "\n",
    "            # Extract the values from the response\n",
    "            response_text = response.choices[0].message.content\n",
    "            print(\"Response Text:\", response_text)\n",
    "            \n",
    "            extraction_tag = re.findall(r\"<>\", response_text) # Put in tags what it is you want returned\n",
    "\n",
    "            # Print the results\n",
    "            for result in extraction_tag:\n",
    "                print(f\"Extracted: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcd6c5-1e77-43aa-a211-52d7b4a5091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\"\n",
    "\n",
    "common_terms = []\n",
    "\n",
    "pdf_folder = get_folder_path()\n",
    "\n",
    "extract_and_query(pdf_folder, api_key, common_terms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
